{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giovannasantoloni/Projetos-de-Sistemas-Inteligentes-de-Apoio-Decis-o/blob/main/Projeto_Final_Curso_BI_Master_2021_1_Giovanna_Dohnert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A-0xp8cx2Av"
      },
      "source": [
        "# Projeto Final Curso BI Master 2021-1\n",
        "> Por Giovanna Santoloni Dohnert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEqYs6BQzQo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dffc6b87-95a0-4970-c0e8-54556e205c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Montagem do Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MbV235WEzt6K"
      },
      "outputs": [],
      "source": [
        "#Importar Bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from glob import glob\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBY3Hu2Q0mWY"
      },
      "outputs": [],
      "source": [
        "#Importar Aplicações\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy import ndimage, misc\n",
        "import skimage\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.models.cloning import training\n",
        "from tensorflow.keras.layers import Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUpt76Qz8TDh"
      },
      "outputs": [],
      "source": [
        "# Caminho da Base de Dados\n",
        "import os\n",
        "workdir_path = '/content/drive/My Drive/Projeto Final BI/images' \n",
        "os.chdir(workdir_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do dataset\n",
        "full_dataset = r'/content/drive/My Drive/Projeto Final BI/images'"
      ],
      "metadata": {
        "id": "y9D39u210jmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição de Parâmetros:\n",
        "A definição de parâmetros em um modelo de classificação de imagens é essencial para que o modelo possa aprender a partir dos dados de treinamento e, posteriormente, ser capaz de classificar novas imagens de forma precisa. A escolha adequada dos parâmetros pode melhorar significativamente a precisão do modelo e sua capacidade de generalização para novos dados. \n"
      ],
      "metadata": {
        "id": "YPXzkIpL6is5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKjcN-4v0xDc"
      },
      "outputs": [],
      "source": [
        "#Definição de Parâmetros\n",
        "\n",
        "#Número de Classes \n",
        "n_classes = 9\n",
        "\n",
        "#Tamanho das Imagens\n",
        "target_size = (224, 224)\n",
        "\n",
        "#Tamanho do Lote para Treinamento\n",
        "batch_size = 32\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separando o Conjunto de Dados em Treino, Validação e Teste\n",
        "\n",
        "Separamos o conjunto de dados em treino, validação e teste a fim de avaliar o desempenho do modelo frente a diferentes dados e garantir que ele seja capaz de generalizar de maneira adequada. \n",
        "\n",
        "•\tConjunto de Treino: usado para treinar o modelo, ajustar os pesos e os parâmetros do modelo com base nos dados de treinamento.\n",
        "\n",
        "•\tConjunto de Validação: usado para avaliar o desempenho do modelo em dados que ele não viu durante o treinamento e otimizar os parâmetros do modelo para obter um melhor desempenho.\n",
        "\n",
        "•\tConjunto de Teste: usado para avaliar o desempenho final do modelo em dados completamente novos que não foram usados para treinamento ou validação."
      ],
      "metadata": {
        "id": "11BwX4If6rE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "\n",
        "O data augmentation foi utilizada para aumentar a quantidade de dados de treinamento do modelo, através da geração de novas amostras a partir das amostras existentes, aplicando transformações como rotação, espelhamento (...) entre outros."
      ],
      "metadata": {
        "id": "-JOQzswx9FcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando o Conjunto de Dados em Treino e Validação\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2, rotation_range=20, # aumentando a variabilidade de dados\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_dataset = image_generator.flow_from_directory(batch_size=batch_size, \n",
        "                                                    directory=full_dataset ,\n",
        "                                                    shuffle = True,\n",
        "                                                    target_size =target_size,\n",
        "                                                    subset =\"training\",\n",
        "                                                    class_mode = 'categorical')\n",
        "\n",
        "validation_dataset = image_generator.flow_from_directory(batch_size=batch_size, \n",
        "                                                    directory=full_dataset,\n",
        "                                                    shuffle = True,\n",
        "                                                    target_size =target_size,\n",
        "                                                    subset =\"validation\",\n",
        "                                                    class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spXUdDwNIaAu",
        "outputId": "710161f8-23db-4c20-b23c-4447dc3a688b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4239 images belonging to 9 classes.\n",
            "Found 1055 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxRhFgoH5lLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07a14d0-c3cf-4e58-8578-26eea79d8bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5294 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "# Separando o conjunto de Teste\n",
        "image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_dataset = image_generator.flow_from_directory(batch_size=batch_size, \n",
        "                                                    directory=full_dataset,\n",
        "                                                    shuffle = True,\n",
        "                                                    target_size =target_size,\n",
        "                                                    class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilização do Transfer Learning\n",
        "O uso de Transfer Learning e pesos pré-treinados do modelo VGG16 ajuda a melhorar a precisão do modelo de classificação de imagens, a reduzir o tempo e o custo de treinamento e a lidar com conjuntos de dados pequenos.\n"
      ],
      "metadata": {
        "id": "6RKSutGu627c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVFbpA5bh40S"
      },
      "outputs": [],
      "source": [
        "# carregar a arquitetura VGG16 pré-treinada\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(*target_size, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "CPdjhWFQjzfP"
      },
      "outputs": [],
      "source": [
        "# adicionar camadas adicionais ao modelo\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x) \n",
        "\n",
        "# Adicionamos uma camada de dropout de 0,5, o que significa que metade dos neurônios da camada anterior serão aleatoriamente desativados\n",
        "# durante o treinamento, para evitar overfitting.\n",
        "\n",
        "x = Dropout(0.5)(x)  \n",
        "\n",
        "predictions = Dense(n_classes, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "sPuuTzGllGqT"
      },
      "outputs": [],
      "source": [
        "# criar modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# congelar as camadas da base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8YSVJbe1le6T"
      },
      "outputs": [],
      "source": [
        "# compilar o modelo\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "29wwz44yiWSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72f5537-de78-485b-eba4-23223c543af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "133/133 [==============================] - 120s 891ms/step - loss: 1.3495 - acc: 0.5414 - val_loss: 1.1446 - val_acc: 0.5858\n",
            "Epoch 2/10\n",
            "133/133 [==============================] - 119s 895ms/step - loss: 1.1978 - acc: 0.5891 - val_loss: 1.1398 - val_acc: 0.5791\n",
            "Epoch 3/10\n",
            "133/133 [==============================] - 116s 875ms/step - loss: 1.1436 - acc: 0.5971 - val_loss: 1.0847 - val_acc: 0.6095\n",
            "Epoch 4/10\n",
            "133/133 [==============================] - 119s 897ms/step - loss: 1.1025 - acc: 0.6112 - val_loss: 1.0632 - val_acc: 0.6218\n",
            "Epoch 5/10\n",
            "133/133 [==============================] - 137s 1s/step - loss: 1.0602 - acc: 0.6251 - val_loss: 1.0423 - val_acc: 0.6057\n",
            "Epoch 6/10\n",
            "133/133 [==============================] - 119s 892ms/step - loss: 1.0375 - acc: 0.6310 - val_loss: 1.0354 - val_acc: 0.6171\n",
            "Epoch 7/10\n",
            "133/133 [==============================] - 115s 868ms/step - loss: 1.0334 - acc: 0.6299 - val_loss: 1.0299 - val_acc: 0.6360\n",
            "Epoch 8/10\n",
            "133/133 [==============================] - 133s 999ms/step - loss: 1.0140 - acc: 0.6405 - val_loss: 1.0020 - val_acc: 0.6284\n",
            "Epoch 9/10\n",
            "133/133 [==============================] - 117s 878ms/step - loss: 1.0034 - acc: 0.6402 - val_loss: 1.0311 - val_acc: 0.6360\n",
            "Epoch 10/10\n",
            "133/133 [==============================] - 114s 861ms/step - loss: 0.9792 - acc: 0.6466 - val_loss: 1.0368 - val_acc: 0.6227\n"
          ]
        }
      ],
      "source": [
        "# Treinar o modelo\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=len(train_dataset),\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    validation_steps=len(validation_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo com conjunto de teste\n",
        "y_pred = model.predict(test_dataset)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = test_dataset.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-Fo15aGBMmM",
        "outputId": "b868e089-79f7-43fd-fb54-442d0ba0bbf8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166/166 [==============================] - 37s 220ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando a Matriz de Confusão\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matriz de Confusão:\\n\", conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owf7-kem_1T5",
        "outputId": "db7afa44-4a0b-4ded-a39c-085ae1ae4ffd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão:\n",
            " [[  63    0    0   93    0  822   13]\n",
            " [   0    0    0    0    0    3    0]\n",
            " [  10    0    0   14    0  157    3]\n",
            " [  65    0    0   88    0  679    6]\n",
            " [   8    0    1   18    0  150    4]\n",
            " [ 195    0    0  321    0 2342   30]\n",
            " [  16    0    0   21    0  170    2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusões \n",
        "\n",
        "O modelo apresentou um desempenho razoável, contudo ainda parece sofrer com overfitting, já que a acurácia no conjunto de validação apresenta-se consideravelmente menor do que a acurácia no conjunto de treinamento. Isso pode ser observado nas diferenças entre as acurácias do conjunto de treinamento e validação nas epochs 1, 2, 3 e 5.\n",
        "\n",
        "O valor da função de perda (loss) no conjunto de validação também não reduz consistentemente com as epochs, o que sugere que o modelo pode estar estagnado do ponto de vista de aprendizado. Em resumo,  o modelo possa se beneficiará de ajustes nos hiperparâmetros para otimizar seu desempenho.                                                                \n",
        "\n",
        "A partir da matriz de confusão, podemos observar que o modelo não está performando bem para algumas classes específicas. Por exemplo, para a classe 2, não foi possível prever nenhuma raça corretamente, o que indica que o modelo precisa ser melhorado para esta classe. O modelo também apresentou baixo desempenho para as classes 1, 4 e 7.\n",
        "\n",
        "Podemos calcular a acurácia do modelo a partir da matriz de confusão, o que aponta para o percentual de corretas em relação ao total de predições: A acurácia é de aproximadamente 53,8%."
      ],
      "metadata": {
        "id": "a9J27OmU5zWY"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5Y6Y33AmQdX1ccKXXc2fa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}